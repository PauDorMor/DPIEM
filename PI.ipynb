{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PauDorMor/DPIEM/blob/main/PI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DPIEM\n",
        "En el siguiente codigo se muestra y se trata de explicar el funcionamiento completo del codigo, el cual tiene la finalidad de poder clasificar e identificar EM disponibles en un espacio hospitalario"
      ],
      "metadata": {
        "id": "RQzv-dxqIGPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importe de librerias"
      ],
      "metadata": {
        "id": "oTnosLNCIamE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "67c3e95b",
        "outputId": "454905a6-fffe-4226-ba60-f91289746f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        }
      ],
      "source": [
        "pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgODsRXR79dE"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from scipy.special import softmax\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracción de imagenes y carpetas de la base de datos"
      ],
      "metadata": {
        "id": "o1XbK3QxRJkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9edc3426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87617b3-2213-4b17-9501-02eed33cffff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in medical-equipment-detection-3 to tfrecord:: 100%|██████████| 830128/830128 [00:33<00:00, 24905.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to medical-equipment-detection-3 in tfrecord:: 100%|██████████| 11/11 [00:04<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /content/medical-equipment-detection-3\n"
          ]
        }
      ],
      "source": [
        "#Datos de la sesion de roboflow\n",
        "ROBOFLOW_API_KEY = \"ysXFekfRklPYfXPY5kQa\"\n",
        "ROBOFLOW_WORKSPACE = \"pau-dm-quidt\"\n",
        "ROBOFLOW_PROJECT = \"medical-equipment-detection-t5ltj\"\n",
        "ROBOFLOW_VERSION = 3\n",
        "\n",
        "rf = Roboflow(api_key=\"ysXFekfRklPYfXPY5kQa\")\n",
        "project = rf.workspace(\"pau-dm-quidt\").project(\"medical-equipment-detection-t5ltj\")\n",
        "\n",
        "# Descarga del dataset, los datos estan en formato TF.Record\n",
        "dataset = project.version(ROBOFLOW_VERSION).download(\"tfrecord\")\n",
        "\n",
        "print(f\"Dataset downloaded to: {dataset.location}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dfd46dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98b10aa-c7c8-44a5-e8d7-00d034c2adee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenido de la Base de datos '/content/medical-equipment-detection-3':\n",
            "medical-equipment-detection-3/\n",
            "    README.dataset.txt\n",
            "    README.roboflow.txt\n",
            "    valid/\n",
            "        medical-euipment-detection.tfrecord\n",
            "        medical-euipment-detection_label_map.pbtxt\n",
            "    train/\n",
            "        medical-euipment-detection.tfrecord\n",
            "        medical-euipment-detection_label_map.pbtxt\n",
            "    test/\n",
            "        medical-euipment-detection.tfrecord\n",
            "        medical-euipment-detection_label_map.pbtxt\n"
          ]
        }
      ],
      "source": [
        "roboflow_dataset_path = dataset.location\n",
        "\n",
        "print(f\"Contenido de la Base de datos '{roboflow_dataset_path}':\")\n",
        "for root, dirs, files in os.walk(roboflow_dataset_path):\n",
        "    level = root.replace(roboflow_dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 4 * (level)\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 4 * (level + 1)\n",
        "    for f in files:\n",
        "        print(f'{subindent}{f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8851c084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b3e15f-a922-4fcc-e91f-e0911e135f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases únicas detectadas : ['Anesthesia Machine', 'BI', 'C-arm', 'Desf', 'ECG', 'ESU', 'EtO', 'MSV', 'US', 'VM', 'X-Ray']\n",
            "Número de clases: 11\n",
            "Numero de clase asociado a partir del ID de clase: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10}\n",
            "Nombre y numero de clase : {0: 'Anesthesia Machine', 1: 'BI', 2: 'C-arm', 3: 'Desf', 4: 'ECG', 5: 'ESU', 6: 'EtO', 7: 'MSV', 8: 'US', 9: 'VM', 10: 'X-Ray'}\n"
          ]
        }
      ],
      "source": [
        "# Ruta de la base de datos en los archivos\n",
        "Ruta_general = '/content/medical-equipment-detection-3'\n",
        "\n",
        "# Ruta para la extracción de etiquetas, en este caso se utiliza la carpeta de entrenar, pero puede cambiar entre cualquiera\n",
        "train_label_map_dir = os.path.join(Ruta_general, 'train')\n",
        "label_map_filename = None\n",
        "\n",
        "# Encuentro de datos en el dataset descargado (en formato pbtxt)\n",
        "for file in os.listdir(train_label_map_dir):\n",
        "    if file.endswith('_label_map.pbtxt'):\n",
        "        label_map_filename = file\n",
        "        break\n",
        "\n",
        "label_map_path = os.path.join(train_label_map_dir, label_map_filename)\n",
        "\n",
        "# Almacenamiento de las nombres de las clases tal y como vienen en roboflow\n",
        "raw_class_names = []\n",
        "label_id_to_raw_name = {}\n",
        "with open(label_map_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "    items_blocks = re.findall(r'item\\s*{([^}]*)}', content)\n",
        "    for block in items_blocks:\n",
        "        id_match = re.search(r'id:\\s*(\\d+)', block)\n",
        "        name_match = re.search(r'display_name:\\s*\"([^\"]*)\"', block)\n",
        "        if id_match and name_match:\n",
        "            item_id = id_match.group(1)\n",
        "            item_name = name_match.group(1)\n",
        "            item_name_stripped = item_name.strip()\n",
        "            label_id_to_raw_name[int(item_id)] = item_name_stripped\n",
        "            raw_class_names.append(item_name_stripped)\n",
        "\n",
        "# Enlistado de los nombres de las clases\n",
        "unique_class_names = []\n",
        "seen_names = set()\n",
        "for name in raw_class_names:\n",
        "    if name not in seen_names:\n",
        "        unique_class_names.append(name)\n",
        "        seen_names.add(name)\n",
        "\n",
        "# Toma de referencia de los nombres que se usaran mas adelante\n",
        "# Ademas de ello es para referenciarlo con el numero asociado a la clase que pertenece\n",
        "class_names = unique_class_names\n",
        "num_unique_classes = len(class_names)\n",
        "\n",
        "#Asignacion entre el ID de la clase y el numero definido\n",
        "label_id_to_unique_class_idx = {}\n",
        "for label_id, raw_name in label_id_to_raw_name.items():\n",
        "    if raw_name in class_names:\n",
        "        label_id_to_unique_class_idx[label_id] = class_names.index(raw_name)\n",
        "    else:\n",
        "        # En caso de que no se encuentre una relacion entre el ID de los datos crudos y la imagen o dato, este no se eliminara, solo se indicara como desconocido\n",
        "        label_id_to_unique_class_idx[label_id] = -1\n",
        "\n",
        "print(\"Clases únicas detectadas :\", class_names)\n",
        "print(\"Número de clases:\", num_unique_classes)\n",
        "print(\"Numero de clase asociado a partir del ID de clase:\", label_id_to_unique_class_idx)\n",
        "print(\"Nombre y numero de clase :\", {idx: name for idx, name in enumerate(class_names)})\n",
        "\n",
        "# Variables globales uasadas para el downstream\n",
        "num_classes = num_unique_classes\n",
        "\n",
        "#Añade robuztes al modelo\n",
        "keys_tensor = tf.constant(list(label_id_to_unique_class_idx.keys()), dtype=tf.int64)\n",
        "values_tensor = tf.constant(list(label_id_to_unique_class_idx.values()), dtype=tf.int64)\n",
        "initializer = tf.lookup.KeyValueTensorInitializer(keys_tensor, values_tensor)\n",
        "label_lookup_table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo el siguiente codigo seria como un post-edicion para correlacionar las clases, esto servira para la extraccion de caracteristicas y la correlacion entre la imagen y los datos que se encuentren en ella, ademas de la clase a la que pertenece"
      ],
      "metadata": {
        "id": "mqkZts9gQ57K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa6c111c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f679bb3-fe83-4b36-d5c2-89037edd1a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Algunos ejemplos del dataset:\n",
            "  Datos de la imagen: (224, 224, 3), Numero de clase: 8 (Class: US)\n",
            "  Datos de la imagen: (224, 224, 3), Numero de clase: 9 (Class: VM)\n",
            "  Datos de la imagen: (224, 224, 3), Numero de clase: 3 (Class: Desf)\n"
          ]
        }
      ],
      "source": [
        "# Define la carpeta de la cual se extraeran las imagenes para la evaluacion de modelo\n",
        "tfrecord_file_path = os.path.join(Ruta_general, 'train', 'medical-euipment-detection.tfrecord')\n",
        "\n",
        "def parse_tf_example(example_proto):\n",
        "    # Sienta las bases para la extraccion de caracteristicas\n",
        "    feature_description = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "    }\n",
        "\n",
        "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "    #Renombra a img_tensor para evitar sobreponer los datos\n",
        "    img_tensor = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n",
        "    img_tensor = tf.image.resize(img_tensor, [224, 224])\n",
        "    img_tensor = tf.cast(img_tensor, tf.float32)\n",
        "\n",
        "    labels_tensor = example['image/object/class/label'].values\n",
        "\n",
        "    #Comprueba que hayan todas las etiquetas, en caso de que no esten, las evalua mas tarde y se indican con -1\n",
        "    if tf.size(labels_tensor) > 0:\n",
        "        raw_label_id = labels_tensor[0]\n",
        "        unique_class_idx = label_lookup_table.lookup(raw_label_id)\n",
        "    else:\n",
        "        unique_class_idx = tf.constant(-1, dtype=tf.int64)\n",
        "\n",
        "    return img_tensor, unique_class_idx\n",
        "\n",
        "# Creacion del dataset\n",
        "raw_dataset = tf.data.TFRecordDataset(tfrecord_file_path)\n",
        "\n",
        "# Mapea el emparejamiento de los dos datos\n",
        "parsed_dataset_with_sentinel = raw_dataset.map(parse_tf_example)\n",
        "\n",
        "# Filtra los datos sin clase, asigna -1\n",
        "parsed_dataset = parsed_dataset_with_sentinel.filter(lambda image, label: tf.not_equal(label, -1))\n",
        "\n",
        "#Muestra algunos ejemplos\n",
        "print(\"\\n Algunos ejemplos del dataset:\")\n",
        "class_idx_to_name_map_for_print = {idx: name for idx, name in enumerate(class_names)}\n",
        "for image, unique_class_idx in parsed_dataset.take(3):\n",
        "    print(f\"  Datos de la imagen: {image.shape}, Numero de clase: {unique_class_idx.numpy()} (Class: {class_idx_to_name_map_for_print.get(unique_class_idx.numpy(), 'Unknown')})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inicio de modelo de extracción de caracteristicas"
      ],
      "metadata": {
        "id": "68JxkTySRadb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deNJ23YQdK9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f2d632-1d5f-4ad4-82fd-5eb7f923839c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Inicio del modelo de extraccion de caracteristicas\n",
        "#top=false ayuda a eliminar capas que no aporten al modelo\n",
        "#pooling=avg ayuda a la formacion del vector de caracteristicas\n",
        "model_vgg = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "785aabe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb6961e-c82b-44f6-a7eb-06a13f6d828b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cuenta con 32 imagenes por lote\n",
            "Numero de clases unicas: 11\n"
          ]
        }
      ],
      "source": [
        "#tamaño del lote\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Inicio de procesamiento por VGG16\n",
        "def apply_vgg16_preprocessing_and_label_mapping(image, unique_class_idx):\n",
        "    image = vgg16_preprocess(image)\n",
        "    return image, unique_class_idx\n",
        "#Se aplica el procesamiento aleatorio por lotes y los datos unicos de cada imagen\n",
        "train_dataset = parsed_dataset.map(apply_vgg16_preprocessing_and_label_mapping)\n",
        "\n",
        "#Mezcla, agrupa y precarga las imagenes\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"Dataset cuenta con {BATCH_SIZE} imagenes por lote\")\n",
        "print(f\"Numero de clases unicas: {num_classes}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_cell_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9151446-d0d6-4103-9e9f-5f7179347a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features from the dataset using VGG16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22it [07:09, 19.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraccion de caracteristicas completa, son : 684\n",
            "Forma de las caracteristicas y las etiquetas: (684, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Inicializa listas para las caracteristicas y las etiquetas\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"Extracting features from the dataset using VGG16...\")\n",
        "\n",
        "#Itera el conjunto de datos preprocesados para extraer sus caracteristicas\n",
        "#Utiliza VGG16 sin capas superiores para la extraccion de caracteristicas\n",
        "for images, labels in tqdm(train_dataset):\n",
        "    features = model_vgg.predict(images, verbose=0)\n",
        "\n",
        "   #Amplia la lista con las caracteristicas y etiquetas asociadas\n",
        "    all_features.extend(features)\n",
        "    all_labels.extend(labels.numpy())\n",
        "\n",
        "#Convierte la lista a datos de numpy\n",
        "all_features = np.array(all_features)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "print(f\"Extraccion de caracteristicas completa, son : {len(all_labels)}\")\n",
        "print(f\"Forma de las caracteristicas y las etiquetas: {all_features.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento y evaluacion del modelo de clasificación"
      ],
      "metadata": {
        "id": "875cfRu6Wk6q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_cell_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89677b51-f9a9-4b51-b8d6-15afd978a1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Ciclo 1 ---\n",
            "Precisión: 0.8613\n",
            "Exactitud (macro): 0.8832\n",
            "Recall (macro): 0.8667\n",
            "F1-Score (macro): 0.8685\n",
            "Kappa: 0.8437\n",
            "\n",
            "--- Ciclo 2 ---\n",
            "Precisión: 0.7664\n",
            "Exactitud (macro): 0.7794\n",
            "Recall (macro): 0.7312\n",
            "F1-Score (macro): 0.7436\n",
            "Kappa: 0.7367\n",
            "\n",
            "--- Ciclo 3 ---\n",
            "Precisión: 0.7883\n",
            "Exactitud (macro): 0.7346\n",
            "Recall (macro): 0.7386\n",
            "F1-Score (macro): 0.7327\n",
            "Kappa: 0.7619\n",
            "\n",
            "--- Ciclo 4 ---\n",
            "Precisión: 0.7737\n",
            "Exactitud (macro): 0.7605\n",
            "Recall (macro): 0.7795\n",
            "F1-Score (macro): 0.7522\n",
            "Kappa: 0.7466\n",
            "\n",
            "--- Ciclo 5 ---\n",
            "Precisión: 0.7206\n",
            "Exactitud (macro): 0.7178\n",
            "Recall (macro): 0.6819\n",
            "F1-Score (macro): 0.6918\n",
            "Kappa: 0.6855\n",
            "\n",
            "--- Cross-Validation Results ---\n",
            "Precision promedio: 0.7821 (Std: 0.0456)\n",
            "Exactitud promedio: 0.7751 (Std: 0.0580)\n",
            "Recall promedio: 0.7596 (Std: 0.0619)\n",
            "F1 promedio: 0.7577 (Std: 0.0591)\n",
            "Kappa promedio: 0.7549 (Std: 0.0513)\n",
            "Clasificador entrenado con todo el dataset.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Inicializa el nummero de elementos a extraer\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "kappas = []\n",
        "\n",
        "#Define el clasificador y se utiliza el modelo SVC\n",
        "clf = LinearSVC(random_state=42, dual=True, max_iter=1000000)\n",
        "\n",
        "#Define el numero de \"ciclos\" de evaluacion del modelo\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(all_features, all_labels)):\n",
        "    print(f\"\\n--- Ciclo {fold+1} ---\")\n",
        "    X_train, X_test = all_features[train_index], all_features[test_index]\n",
        "    y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    precision = metrics.precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    recall = metrics.recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    f1 = metrics.f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "    kappa = metrics.cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1s.append(f1)\n",
        "    kappas.append(kappa)\n",
        "\n",
        "    print(f\"Precisión: {accuracy:.4f}\")\n",
        "    print(f\"Exactitud (macro): {precision:.4f}\")\n",
        "    print(f\"Recall (macro): {recall:.4f}\")\n",
        "    print(f\"F1-Score (macro): {f1:.4f}\")\n",
        "    print(f\"Kappa: {kappa:.4f}\")\n",
        "\n",
        "print(\"\\n--- Cross-Validation Results ---\")\n",
        "print(f\"Precision promedio: {np.mean(accuracies):.4f} (Std: {np.std(accuracies):.4f})\")\n",
        "print(f\"Exactitud promedio: {np.mean(precisions):.4f} (Std: {np.std(precisions):.4f})\")\n",
        "print(f\"Recall promedio: {np.mean(recalls):.4f} (Std: {np.std(recalls):.4f})\")\n",
        "print(f\"F1 promedio: {np.mean(f1s):.4f} (Std: {np.std(f1s):.4f})\")\n",
        "print(f\"Kappa promedio: {np.mean(kappas):.4f} (Std: {np.std(kappas):.4f})\")\n",
        "\n",
        "#Re entrenamiento de todo el dataset\n",
        "final_clf = LinearSVC(random_state=42, dual=True, max_iter=1000000)\n",
        "final_clf.fit(all_features, all_labels)\n",
        "print(\"Clasificador entrenado con todo el dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_cell_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0553389-3c0a-478e-ba10-744b01c4205e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clasificador guardado en : /content/drive/MyDrive/A - FPDI/medical_equipment_classifier.joblib\n"
          ]
        }
      ],
      "source": [
        "# Ruta para guardar el clasificador\n",
        "classifier_save_path = '/content/drive/MyDrive/A - FPDI/medical_equipment_classifier.joblib'\n",
        "\n",
        "# Obtener el directorio de la ruta del archivo\n",
        "save_directory = os.path.dirname(classifier_save_path)\n",
        "\n",
        "# Crear el directorio si no existe\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Guardar el clasificador\n",
        "joblib.dump(final_clf, classifier_save_path)\n",
        "print(f\"Clasificador guardado en : {classifier_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Puesta en marcha del modelo"
      ],
      "metadata": {
        "id": "oWLJQgfGRoPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se carga el modelo preentrenado para la extraccion de caracteristicas, ademas que hace una doble verificacion del modelo de entrenamiento"
      ],
      "metadata": {
        "id": "XCog7OnkeKMV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "new_cell_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0dece4e-ae2b-4f3d-ac51-a160d6c9023b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraccion de caracteristicas de la imagen : /content/Radiopaco.png\n",
            "ID de clase predecida: 7, Clase predecida: MSV\n",
            "Prediccion completa.\n"
          ]
        }
      ],
      "source": [
        "model_vgg_inference = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "classifier_load_path = '/content/drive/MyDrive/A - FPDI/medical_equipment_classifier.joblib'\n",
        "loaded_clf = joblib.load(classifier_load_path)\n",
        "\n",
        "#Nueva ruta de imagen a clasificar\n",
        "new_image_path = '/content/Radiopaco.png'\n",
        "\n",
        "# Preprocesamiento de la imagen\n",
        "def extract_features_single_image(img_path, feature_extractor_model, preprocess_func):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_func(x)\n",
        "    features = feature_extractor_model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "# Ectraccion de caracteristicas de la nueva imagen\n",
        "print(f\"Extraccion de caracteristicas de la imagen : {new_image_path}\")\n",
        "new_image_features = extract_features_single_image(new_image_path, model_vgg_inference, vgg16_preprocess)\n",
        "\n",
        "# Reestructuracion de la imagen para hacer la prediccion\n",
        "new_image_features = new_image_features.reshape(1, -1)\n",
        "\n",
        "# Inicio de la prediccion\n",
        "predicted_label_id = loaded_clf.predict(new_image_features)[0]\n",
        "\n",
        "#Relacion entre el nombre de la clase utilizando nombres globales\n",
        "# En caso de que no encuentre el nombre de la clase, lo menciona\n",
        "if 0 <= predicted_label_id < len(class_names):\n",
        "    predicted_class_name = class_names[predicted_label_id]\n",
        "    print(f\"ID de clase predecida: {predicted_label_id}, Clase predecida: {predicted_class_name}\")\n",
        "else:\n",
        "    print(f\"ID de clase predecida: {predicted_label_id}, No hay nombre de clase asociado.\")\n",
        "\n",
        "print(\"Prediccion completa.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo modificado con %"
      ],
      "metadata": {
        "id": "H4qM1E36gvbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc90d18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d1a6b9-f177-4578-f1b9-0b35dfe3ba61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clasificador cargado de : /content/drive/MyDrive/A - FPDI/medical_equipment_classifier.joblib\n",
            "Extrayendo caracteristicas de la nueva imagen: /content/C-Arm.webp\n",
            "ID de clase predicho: 2, Clase predicha: C-arm\n",
            "Confianza de modelo (aprox): 54.48%\n",
            "Prediccion completa.\n"
          ]
        }
      ],
      "source": [
        "model_vgg_inference = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "classifier_load_path = '/content/drive/MyDrive/A - FPDI/medical_equipment_classifier.joblib'\n",
        "loaded_clf = joblib.load(classifier_load_path)\n",
        "print(f\"Clasificador cargado de : {classifier_load_path}\")\n",
        "\n",
        "#Incluye aqui la ruta de la imagen a evaluar\n",
        "new_image_path = '/content/C-Arm.webp'\n",
        "\n",
        "def extract_features_single_image(img_path, feature_extractor_model, preprocess_func):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0) # agrega la dimensión del conjunto de imágenes\n",
        "    x = preprocess_func(x)\n",
        "    features = feature_extractor_model.predict(x, verbose=0)\n",
        "    return features.flatten()\n",
        "\n",
        "print(f\"Extrayendo caracteristicas de la nueva imagen: {new_image_path}\")\n",
        "new_image_features = extract_features_single_image(new_image_path, model_vgg_inference, vgg16_preprocess)\n",
        "\n",
        "new_image_features = new_image_features.reshape(1, -1)\n",
        "\n",
        "predicted_label_id = loaded_clf.predict(new_image_features)[0]\n",
        "\n",
        "# Da un valor dependiendo al nivel de emparejamiento resultante\n",
        "decision_scores = loaded_clf.decision_function(new_image_features)[0] # obtiene la puntuación de la muestra simple\n",
        "\n",
        "#Se da la confianza del modelo como porcentaje, mas no es el valor de fidelidad del modelo\n",
        "confidences = softmax(decision_scores)\n",
        "\n",
        "# Obtencion de la confianza del modelo y lo convierte a porcentaje\n",
        "predicted_confidence = confidences[predicted_label_id] * 100\n",
        "\n",
        "if 0 <= predicted_label_id < len(class_names):\n",
        "    predicted_class_name = class_names[predicted_label_id]\n",
        "    print(f\"ID de clase predicho: {predicted_label_id}, Clase predicha: {predicted_class_name}\")\n",
        "    print(f\"Confianza de modelo (aprox): {predicted_confidence:.2f}%\")\n",
        "else:\n",
        "    print(f\"ID de clase: {predicted_label_id}, No se encontro una clase con esos datos.\")\n",
        "\n",
        "print(\"Prediccion completa.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *El codigo fue realizado con ayuda de Gemini Ai*"
      ],
      "metadata": {
        "id": "nj0iBEcj1h_s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfrCR6Y4ePcKDN9JDU2rrX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}